import json
import os
import argparse
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ì´ PNG ì €ì¥ìš©
import numpy as np
from pathlib import Path
from collections import defaultdict

def load_workload_json(file_path):
    """ì›Œí¬ë¡œë“œ JSON íŒŒì¼ì„ ë¡œë“œí•˜ê³  queriesì™€ statisticsë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('queries', []), data.get('statistics', {})
    except Exception as e:
        print(f"Error loading {file_path}: {e}")
        return None, None

def normalize_sampling_method(method, group_mode=False):
    """sampling_methodë¥¼ ê·¸ë£¹í™” ëª¨ë“œì— ë”°ë¼ ì •ê·œí™”í•©ë‹ˆë‹¤.
    
    Args:
        method: ì›ë³¸ sampling_method
        group_mode: Trueì´ë©´ ê·¸ë£¹í™”, Falseì´ë©´ ì›ë³¸ ìœ ì§€
        
    Returns:
        ì •ê·œí™”ëœ sampling_method
    """
    if not group_mode:
        return method
    
    # ê·¸ë£¹í™” ëª¨ë“œ: "db", "histogram" â†’ "DB", ë‚˜ë¨¸ì§€ â†’ "EXISTING"
    if method in ["db", "histogram"]:
        return "DB"
    else:
        return "EXISTING"

def aggregate_sampling_method_per_masking_cnt(queries, group_mode=False):
    """queriesì—ì„œ masking_cntë³„ sampling_method ë¶„í¬ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤.
    
    Args:
        queries: ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
        group_mode: Trueì´ë©´ sampling_methodë¥¼ ê·¸ë£¹í™” (db/histogram â†’ DB, ë‚˜ë¨¸ì§€ â†’ EXISTING)
    """
    # masking_cnt -> {sampling_method: count} êµ¬ì¡°ë¡œ ì €ì¥
    distribution = defaultdict(lambda: defaultdict(int))
    
    for query in queries:
        masking_cnt = query.get('masking_cnt', 0)
        sampling_method = query.get('sampling_method', 'unknown')
        # ê·¸ë£¹í™” ëª¨ë“œ ì ìš©
        normalized_method = normalize_sampling_method(sampling_method, group_mode)
        distribution[masking_cnt][normalized_method] += 1
    
    return distribution

def plot_sampling_method_distribution(distribution, output_path, db_name, benchmark_type, dist_type, method_order=None, group_mode=True):
    """masking_cntë³„ sampling_method ë¶„í¬ë¥¼ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        distribution: masking_cntë³„ sampling_method ë¶„í¬ ë°ì´í„°
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        db_name: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
        benchmark_type: ë²¤ì¹˜ë§ˆí¬ íƒ€ì…
        dist_type: distribution íƒ€ì… (uniform, zipf_random, zipf_query_len ë“±)
        method_order: sampling_method ìˆœì„œ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì•ŒíŒŒë²³ ìˆœì„œë¡œ ì •ë ¬)
        group_mode: Trueì´ë©´ ê·¸ë£¹í™” ëª¨ë“œ (db/histogram â†’ DB, ë‚˜ë¨¸ì§€ â†’ EXISTING)
    """
    if not distribution:
        print(f"  âš ï¸  {db_name}: No distribution data. Skipping...")
        return
    
    # masking_cntë¥¼ ì •ë ¬í•˜ê³  sampling_method ëª©ë¡ ìˆ˜ì§‘
    masking_cnts = sorted(distribution.keys())
    all_sampling_methods_set = set()
    for cnt_dict in distribution.values():
        all_sampling_methods_set.update(cnt_dict.keys())
    
    # method_order ì„¤ì •
    if group_mode:
        # ê·¸ë£¹í™” ëª¨ë“œ: DB, EXISTING ìˆœì„œ
        method_order = ["DB", "EXISTING"]
    else:
        # ì›ë³¸ ëª¨ë“œ: ê¸°ë³¸ ìˆœì„œ
        method_order = ["original", "db", "histogram", "existing", "example_value"]
    
    if method_order is not None:
        # method_orderì— ìˆëŠ” ê²ƒë§Œ í¬í•¨í•˜ê³ , ìˆœì„œ ìœ ì§€
        all_sampling_methods = [m for m in method_order if m in all_sampling_methods_set]
        # method_orderì— ì—†ëŠ” ê²ƒë“¤ì€ ë’¤ì— ì¶”ê°€
        remaining = sorted([m for m in all_sampling_methods_set if m not in method_order])
        all_sampling_methods = all_sampling_methods + remaining
    else:
        all_sampling_methods = sorted(all_sampling_methods_set)
    
    if not all_sampling_methods:
        print(f"  âš ï¸  {db_name}: No sampling methods found. Skipping...")
        return
    
    # ê° sampling_methodë³„ë¡œ masking_cntì— ë”°ë¥¸ ê°’ ì¶”ì¶œ
    method_data = {}
    for method in all_sampling_methods:
        method_data[method] = [distribution.get(mc, {}).get(method, 0) for mc in masking_cnts]
    
    # ê·¸ë˜í”„ ìƒì„±
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # ê° ê·¸ë£¹ ì‚¬ì´ì— ê°„ê²©ì„ ì£¼ê¸° ìœ„í•´ xì¶• ìœ„ì¹˜ë¥¼ ì¡°ì •
    group_spacing = 1.2  # ê·¸ë£¹ ê°„ ê°„ê²© (1.0ë³´ë‹¤ í¬ë©´ ê°„ê²©ì´ ìƒê¹€)
    x = np.arange(len(masking_cnts)) * group_spacing
    width = 0.2  # sampling_method ê°œìˆ˜ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
    
    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (sampling_method ê°œìˆ˜ì— ë”°ë¼ ìë™ ì¡°ì •)
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F']
    if len(all_sampling_methods) > len(colors):
        # ë” ë§ì€ ìƒ‰ìƒì´ í•„ìš”í•˜ë©´ ì¶”ê°€
        import matplotlib.cm as cm
        colors = cm.tab20(np.linspace(0, 1, len(all_sampling_methods)))
    
    # ê° sampling_methodë³„ ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
    bars_list = []
    for idx, method in enumerate(all_sampling_methods):
        offset = (idx - len(all_sampling_methods)/2 + 0.5) * width
        bars = ax.bar(x + offset, method_data[method], width, 
                     label=method, alpha=0.8, color=colors[idx % len(colors)])
        bars_list.append(bars)
    
    # ë ˆì´ë¸” ì„¤ì •
    ax.set_xlabel('Masking Count', fontsize=12)
    ax.set_ylabel('Count', fontsize=12)
    dist_type_title = dist_type.replace('_', ' ').title()
    ax.set_title(f'{benchmark_type} - {db_name} ({dist_type_title})\nSampling Method Distribution per Masking Count', 
                 fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels([str(mc) for mc in masking_cnts])
    ax.legend()
    ax.grid(axis='y', alpha=0.3)
    
    # ê°’ ë ˆì´ë¸” ì¶”ê°€
    for bars in bars_list:
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{int(height)}',
                       ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Saved: {output_path}")

def main(): 
    parser = argparse.ArgumentParser(description='Analyze sampling method distribution per masking count')
    parser.add_argument('--group-mode', action='store_true', 
                       help='Group sampling methods: db/histogram â†’ DB, others â†’ EXISTING')
    parser.add_argument('--base-dir', type=str, 
                       default="/data/yhyunjun/HybridSQL-Benchmark/workload-construction-2/data/workloads_v16_1k",
                       help='Base directory for workload data (should contain Dev and Train subdirectories)')
    parser.add_argument('--output-dir', type=str,
                       default="/data/yhyunjun/HybridSQL-Benchmark/workload-construction-2/tools/sampling_method_distribution_plots/v17",
                       help='Output directory for plots')
    
    args = parser.parse_args()
    
    base_dir = Path(args.base_dir)
    output_dir = Path(args.output_dir)
    group_mode = args.group_mode
    
    # ê·¸ë£¹í™” ëª¨ë“œì— ë”°ë¼ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì´ë¦„ ë³€ê²½
    if group_mode:
        output_dir = output_dir.parent / f"{output_dir.name}"
    
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # sampling_method ìˆœì„œ ì§€ì • (Noneì´ë©´ ì•ŒíŒŒë²³ ìˆœì„œë¡œ ì •ë ¬)
    method_order = None
    
    datasets = ["BIRD", "EHRSQL", "ScienceBenchmark"]
    splits = ["Dev", "Train"]
    
    # ëª¨ë“  distribution íƒ€ì… ì •ì˜
    distribution_types = [
        ("uniform_rank", "uniform"),
        ("zipf_random", "zipf_random"),
        ("zipf_query_len", "zipf_query_len")
    ]

    # v10 ìš©
    # distribution_types = [
    #     ("uniform", "uniform"),
    #     ("zipf(random)", "zipf_random"),
    #     ("zipf(query_len)", "zipf_query_len")
    # ]
    
    if group_mode:
        print("ğŸ”¹ ê·¸ë£¹í™” ëª¨ë“œ í™œì„±í™”: db/histogram â†’ DB, ë‚˜ë¨¸ì§€ â†’ EXISTING")
    else:
        print("ğŸ”¹ ì›ë³¸ ëª¨ë“œ: sampling_method ê·¸ë£¹í™” ì—†ìŒ")
    
    total_plots = 0
    
    # Devì™€ Train ëª¨ë‘ ì²˜ë¦¬
    for split in splits:
        split_dir = base_dir / split
        if not split_dir.exists():
            print(f"Warning: {split_dir} does not exist. Skipping...")
            continue
        
        print(f"\n{'=' * 60}")
        print(f"ğŸ”¹ Processing {split} split...")
        print(f"{'=' * 60}")
        
        for dataset in datasets:
            dataset_path = split_dir / dataset
            if not dataset_path.exists():
                print(f"Warning: {dataset_path} does not exist. Skipping...")
                continue
            
            print(f"\nğŸ”¹ Processing {split}/{dataset}...")
            
            # ê° DB ë””ë ‰í† ë¦¬ íƒìƒ‰
            for db_dir in dataset_path.iterdir():
                if not db_dir.is_dir():
                    continue
                
                db_name = db_dir.name
                print(f"\n  ğŸ“ {db_name}:")
                
                # ê° distribution íƒ€ì… ì²˜ë¦¬
                for file_pattern, dist_type in distribution_types:
                    workload_file = db_dir / f"{file_pattern}_1k.json"
                    
                    if not workload_file.exists():
                        print(f"    âš ï¸  {dist_type}: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ê±´ë„ˆëœ€...")
                        continue
                    
                    # JSON íŒŒì¼ ë¡œë“œ
                    queries, stats = load_workload_json(workload_file)
                    if queries is None:
                        continue
                    
                    # ë¶„í¬ ë°ì´í„° ì§‘ê³„
                    distribution = aggregate_sampling_method_per_masking_cnt(queries, group_mode=group_mode)
                    
                    if not distribution:
                        print(f"    âš ï¸  {dist_type}: ë¶„í¬ ë°ì´í„° ì—†ìŒ. ê±´ë„ˆëœ€...")
                        continue
                    
                    # split/distribution íƒ€ì…ë³„ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
                    split_output_dir = output_dir / split / dist_type
                    split_output_dir.mkdir(exist_ok=True, parents=True)
                    
                    # ê·¸ë˜í”„ ìƒì„±
                    suffix = "_grouped" if group_mode else ""
                    output_path = split_output_dir / f"{dataset}_{db_name}_sampling_method_distribution{suffix}.png"
                    plot_sampling_method_distribution(distribution, output_path, db_name, dataset, dist_type, method_order, group_mode=group_mode)
                    
                    total_plots += 1
                    print(f"    âœ… {dist_type}: ì™„ë£Œ")
    
    print(f"\n{'=' * 60}")
    print(f"ğŸ‰ ì´ {total_plots}ê°œ plotì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_dir}")
    print(f"{'=' * 60}")

if __name__ == "__main__":
    main()

